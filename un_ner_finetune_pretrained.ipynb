{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmVWmBCkR9vF"
      },
      "source": [
        "# Fine Tuning BERT For Named Entity Recognition On United Nations Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmXQ0S05R9vb"
      },
      "source": [
        "[![Open in Layer](https://development.layer.co/assets/badge.svg)](https://app.layer.ai/kaankarakeben/united_nations_ner-finetuning)\n",
        "[![Layer NER](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/kaankarakeben/layer_ner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUE1_LZR9vc"
      },
      "source": [
        "Humans understand the world by putting labels on things and examining how these labels relate to each other. A reflection of this in the natural language processing and information retrieval world is a technique called Named Entity Recognition (NER). The objective is to detect the entity type of segments of text in a document. These entities could be organizations, locations, persons, or others. \n",
        "\n",
        "In this blog post, I will go through an example of learning a named entity recognition model on a specific domain. Instead of creating a NER model from scratch, I will use transfer-learning by taking a pre-trained language model, BERT, trained on a large number of general examples and fine-tune that neural network on a very specific type of domain. \n",
        "\n",
        "Alongside the tutorial on learning a NER model, I will run this project on [Layer](https://layer.ai/) in order to make use of their metadata store for storing and tracking the datasets and model artifacts as well as their free GPU compute instances. \n",
        "\n",
        "Firstly, let's define the problem. We are working with a set of documents from the United Nations (UN). Diplomatic jargon is the norm at the UN and these documents contain many specific entities that we don't encounter in everyday language such as the Office for the Coordination of Humanitarian Affairs of the Secretariat or the Office of the United\n",
        "Nations High Commissioner for Refugees. We would like to automatically detect these entities with their corresponding types. With the entities flagged, we can power many interesting use cases such as information retrieval, question/answering, document similarity, etc. \n",
        "\n",
        "The dataset is generously made available to the public by Leslie Huang. It consists of transcribed speeches given at the UN General Assembly from 1993 to 2016, which were scraped from the UN website, parsed (e.g. from PDF), and cleaned. More than 50,000 tokens were manually annotated for NER tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uURt5H69R9vg"
      },
      "source": [
        "## Installing/Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqGt7NRfR9vg"
      },
      "source": [
        "Let's start by creating a project at Layer so that we can define a reproducible project and dataset and artifacts logged along with parameters for future reference. Layer helps you build, train and track all your machine learning project metadata including ML models and datasets‍ with semantic versioning. It also allows you to use their cloud infrastructure free of charge including access to GPUs. We will work with a pre-trained transformer-based language model; so added processing power is very welcome.\n",
        "\n",
        "We will start by installing the necessary libraries. Afterwards we log in to Layer and initialize our ML project called \"united-nations-ner-finetuning\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zR9xHoUwR9vh",
        "outputId": "00bdb8b8-08f1-4a2d-fd78-1fab591f02ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 30.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 22.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.8 MB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 21.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 13.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 35.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 256 kB 33.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 38.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 46.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 306 kB 44.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 38.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 62.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 47.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 70.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.6 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
            "Reason for being yanked: Segfaults\u001b[0m\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
            "Reason for being yanked: grpcio 1.45.0 was yanked\u001b[0m\n",
            "\u001b[?25h  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for polling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "nbclient 0.6.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython) (0.18.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython) (0.1.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython) (3.0.29)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Installing collected packages: ipython\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n",
            "Successfully installed ipython-7.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.4.post0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, dill, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "Successfully installed datasets-2.2.2 dill-0.3.4 fsspec-2022.5.0 multiprocess-0.70.12.2 responses-0.18.0 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=217552d8805136c7a5d2e691ce81729ac9ecc74134bf38d6e8c0b04ee6c26b67\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Cloning into 'UN-named-entity-recognition'...\n",
            "remote: Enumerating objects: 21580, done.\u001b[K\n",
            "remote: Total 21580 (delta 0), reused 0 (delta 0), pack-reused 21580\u001b[K\n",
            "Receiving objects: 100% (21580/21580), 14.70 MiB | 23.04 MiB/s, done.\n",
            "Resolving deltas: 100% (21095/21095), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install layer --upgrade -qqq\n",
        "!pip install -U ipython\n",
        "\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install seqeval\n",
        "\n",
        "!git clone https://github.com/leslie-huang/UN-named-entity-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ziymlHhR9vh",
        "outputId": "70bcece8-666f-4213-d42b-da084b096bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please open the following link in your web browser. Once logged in, copy the code and paste it here.\n",
            "https://app.layer.ai/oauth/authorize?response_type=code&code_challenge=Qp1EzwxwNrklBufqhZY1EERymw9lX81bEqgLSsghK84&code_challenge_method=S256&client_id=0STDdcnpK48P8A429EAAn93WNuLmViLR&redirect_uri=https://app.layer.ai/oauth/code&scope=offline_access&audience=https://app.layer.ai\n",
            "Code: tnBeddEKGH8d3JejeTYZBbuClTWqzzuVbAKXLDblhCIUG\n",
            "Successfully logged into https://app.layer.ai\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "import layer\n",
        "from layer.decorators import dataset, model, pip_requirements, fabric, resources\n",
        "\n",
        "layer.login()\n",
        "layer.init(\"united-nations-ner-finetuning\")\n",
        "\n",
        "TRAIN_EXAMPLES_RATIO = 0.8\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrGqS6G6R9vi"
      },
      "source": [
        "After setting up the ML metadatastore, we will now clone the Github repository that hosts the dataset files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLZImBtrR9vi"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset is generously [made available to the public](https://github.com/leslie-huang/UN-named-entity-recognition) by Leslie Huang. It consists of transcribed speeches given at the UN General Assembly from 1993 to 2016, which were scraped from the UN website, parsed (e.g. from PDF), and cleaned. More than 50,000 tokens were manually annotated for NER tags.\n",
        "\n",
        "At this step, we will load the tagged documents from both training and test sets and store them in a DataFrame.\n",
        "As you may have noticed, we are using decorators from Layer to define a dataset artifact that will be logged on our cloud project at Layer. By calling \"layer.run()\" we will be running the function \"create_dataset\" on the cloud infrastructure.\n",
        "\n",
        "You may have also noticed we are logging some text metadata with the dataset. This enriches our ML project at the readability and reproducibility level. As code is more often read than written, and more so are ML projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P50mtF-SR9vi"
      },
      "source": [
        "### Exploring the tags\n",
        "The annotation for NER tags follows a specific Named Entity Recognition annotation scheme called IOB-tagging. It stands for Inside-Outside-Beginning. A text document is tagged at the word level and entities sometimes come in word groups. To note the entities that cover a few words we use the Beginning (B) and Inside (I) tags.\n",
        "\n",
        "```\n",
        "Example: Tim Cook works at Apple. \n",
        "[Tim, Cook, works, at, Apple] -> [B-PER, I-PER, O, 0, B-ORG]\n",
        "```\n",
        "\n",
        "Our dataset consists of two columns where each item is a list. In the \"tokens\" column, we have words in the document in a list. In the \"ner_tags\" column, we have the corresponding tags.\n",
        "\n",
        "Craeting a Counter object from the NER tags, we see the following pattern. As expected the most common tag is \"O\" denoting \"Outside\" for words that are not a part of a named entity. The second is the \"I-ORG\" tag denoting organization entities and next in line is \"I-LOC\" meaning location.\n",
        "An interesting find is that while we have Inside (I) tags, we don't have their beginning (B) tags. We also have some typos that have very low representations. To address this we will clean tags and reduce the tag classification space by removing \"I-PRG\", \"I-I-MISC\", \"I-OR\", \"VMISC\", \"I-\", \"0\". \n",
        "\n",
        "```\n",
        "tag\t    value\n",
        "-----------------\n",
        "I-LOC\t    3329\n",
        "O\t    135914\n",
        "I-PER\t    444\n",
        "I-ORG\t    3562\n",
        "I-MISC\t    2649\n",
        "0\t    7\n",
        "I-PRG\t    1\n",
        "I-I-MISC    1\n",
        "I-OR\t    1\n",
        "I-\t    2\n",
        "VMISC\t    1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxX1nnahR9vj",
        "outputId": "fa75d81d-4b10-47ed-f435-8d34683e780b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  un_ner_dataset       ━━━━━━━━━━ DONE [0:00:07]                              \n",
            "    ↳ https://app.layer.ai/kaankarakeben/united-nations-ner-finetuning/datasets \n",
            "    /un_ner_dataset                                                             \n"
          ]
        }
      ],
      "source": [
        "def clean_tags(tags, tags_to_remove):\n",
        "    clean_list = []\n",
        "    for tag in list(tags):\n",
        "        if tag != \"O\" and tag not in tags_to_remove:\n",
        "            clean_list.append(tag)\n",
        "        else:\n",
        "            clean_list.append(\"O\")\n",
        "    return clean_list\n",
        "\n",
        "@dataset(\"un_ner_dataset\")\n",
        "@resources(path=\"./UN-named-entity-recognition\")\n",
        "def create_dataset():\n",
        "    import os\n",
        "    import itertools\n",
        "    import pandas as pd\n",
        "    from collections import Counter\n",
        "    \n",
        "    directories = [\n",
        "        \"./UN-named-entity-recognition/tagged-training/\",\n",
        "        \"./UN-named-entity-recognition/tagged-test/\",\n",
        "    ]\n",
        "    data_files = []\n",
        "    for dir in directories:\n",
        "        for filename in os.listdir(dir):\n",
        "            file_path = os.path.join(dir, filename)\n",
        "\n",
        "            with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
        "                lines = f.readlines()\n",
        "                split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == \"\\n\") if not x]\n",
        "                tokens = [[x.split(\"\\t\")[0] for x in y] for y in split_list]\n",
        "                entities = [[x.split(\"\\t\")[1][:-1] for x in y] for y in split_list]\n",
        "                data_files.append(pd.DataFrame({\"tokens\": tokens, \"ner_tags\": entities}))\n",
        "\n",
        "    dataset = pd.concat(data_files).reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "    # Cleaning and removing bad tags\n",
        "    pre_cleanup_tag_counter = Counter([tag for tags in dataset[\"ner_tags\"] for tag in tags])\n",
        "    tags_to_remove = [\"I-PRG\", \"I-I-MISC\", \"I-OR\", \"VMISC\", \"I-\", \"0\"]\n",
        "    dataset[\"ner_tags\"] = dataset[\"ner_tags\"].apply(lambda x: clean_tags(x, tags_to_remove))\n",
        "    tag_counter = Counter([tag for tags in dataset[\"ner_tags\"] for tag in tags])\n",
        "    dataset_description = \"\"\"The corpus consists of a sample of transcribed speeches given at the UN General Assembly \n",
        "    from 1993-2016, which were scraped from the UN website, parsed (e.g. from PDF), and cleaned. More than 50,000 tokens \n",
        "    in the test data were manually tagged for Named Entity Recognition (O - Not a Named Entity; I-PER - Person; I-ORG - \n",
        "    Organization; I-LOC - Location; I-MISC - Other Named Entity).\"\"\"\n",
        "    layer.log({\"# Examples\": len(dataset)})\n",
        "    layer.log({\"Dataset Description\": dataset_description})\n",
        "    layer.log({\"Source\": \"https://github.com/leslie-huang/UN-named-entity-recognition\"})\n",
        "    layer.log({\"Raw Tags Counter\": pre_cleanup_tag_counter})\n",
        "    layer.log({\"Clean Tags Counter\": tag_counter})\n",
        "\n",
        "    return dataset\n",
        "\n",
        "ner_dataset = create_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzBla27vR9vk"
      },
      "source": [
        "## Model: Fine-tuning Pretrained BERT with PyTorch\n",
        "\n",
        "As stated earlier we will use transfer learning to create our NER model. The pre-trained model we'll use is BERT which large neural network trained on masked language modeling and next sentence prediction tasks. If you are interested in having a deeper understanding, have a look at the [original paper](https://arxiv.org/abs/1810.04805) and this brilliant [blog post](http://jalammar.github.io/illustrated-bert/) by Jay Alammar. The fine-tunning will be a supervised learning effort with our annotated dataset.\n",
        "\n",
        "We will work [HuggingFace](https://huggingface.co/)'s powerful [transformers](https://github.com/huggingface/transformers) library to get the [PyTorch](https://pytorch.org/) implementation of the pre-trained model as well as the tokenizer object that is required to turn our dataset into the input format for BERT. Below is the code to load the tokenizer and store it on our Layer project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "87ac34b4d5be4811a58de0fb1ceed9f4",
            "a057c2c607ba4ba4a5ca5f15579d0ab5",
            "d304f33daf2e442ebafe045d5689aa67",
            "f041d98a6d99436c88f8314b476f86bf",
            "330aae7d5fe1433ca12e177b97cddfc5",
            "4edb4da206724db7a032daea0aae3bbb",
            "86ece372ea304cb5b4890f6d920e4269",
            "bbda1a38a9ec4e509eb9c40051bf3427",
            "ea56c606ec2a4cb0a087634906fe5450",
            "c4b1d9d26be847e1896b3511287fd2d7",
            "cf1712a2ba6a442f998ec49b11c9a570",
            "e0e8ff8fd1204a2cb2816c020b22be17",
            "568b6fb9f0df48fea3eabce81d459eee",
            "7eee4edf3a3e4a9c83b9917efaa4e46c",
            "1c2b41aa75c049dc9bc6ea9f2f5e4b31",
            "81206ea8c2de472dadd8eb46e5a20115",
            "c33e5b507e094bb5bed7ffabdf0e57ec",
            "047e4438fa23453794be01930012a5dd",
            "394cd36238654af99f975be2f4c6623e",
            "70a44ab938054561928c45f85fcaa7bd",
            "d420cac29a7144968f408a5b8ef76977",
            "de8cb135bc7541f48e665c28d59cdfe8",
            "63c2971ec486481fa1802a2c4657e73c",
            "f8f15011a94e4435a4288ac90eea772e",
            "44dbe2e8e7d149258e300870184f012d",
            "398ccf3e12524cdc9a78b54a64436bb8",
            "d0fc4291111f4cfd854197043acbdb89",
            "e3ae477fe10e481c8a8ebe34083ba9ac",
            "988b1898cc214364b0f5cb460feabbae",
            "dc66bd78db5d4e84be8a6d81f53e7dc4",
            "364b87333d934b5393768fc52c4172e1",
            "b2b1abd2d51f4c58b1830c59e7b2aa67",
            "7ea9e0f05e1349138d02ffce69dc66bd",
            "45e937297d484a1d908d0b740820fd61",
            "8000df05e29a498a9b49b28a502c4feb",
            "57a70adb0783425995786c03e29325ce",
            "b615799b4ecd4aea8614d2591fbd29ad",
            "12d3e45a5dde4cfc89c3dc6b5d043f1a",
            "4437d6f248714a1cb16f297bb6bb72bb",
            "217485a83b6a411ebb970ee52436da2d",
            "2bd29a01768c44429554a0a2dc30feae",
            "afc56d692f49429f8ee5ceb8fc72db76",
            "28e31c2aa6784786832fd0db97b87f23",
            "2c881835c3c845a1af8e8e248bfbc674"
          ]
        },
        "id": "CrnnkSCuR9vk",
        "outputId": "58848ad4-1f9b-47a4-ad81-c6281a0172fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87ac34b4d5be4811a58de0fb1ceed9f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0e8ff8fd1204a2cb2816c020b22be17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63c2971ec486481fa1802a2c4657e73c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45e937297d484a1d908d0b740820fd61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  bert-base-uncased-t… ━━━━━━━━━━ DONE [0:00:06]                              \n",
            "    ↳ https://app.layer.ai/kaankarakeben/united-nations-ner-finetuning/models/b \n",
            "    ert-base-uncased-tokenizer?v=1.3                                            \n"
          ]
        }
      ],
      "source": [
        "@pip_requirements(packages=[\"transformers\"])\n",
        "@fabric(\"f-medium\")\n",
        "@model(name=\"bert-base-uncased-tokenizer\")\n",
        "def download_tokenizer():\n",
        "    from transformers import BertTokenizerFast\n",
        "\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "    return tokenizer\n",
        "\n",
        "tokenizer = download_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-guv_ceXR9vl",
        "outputId": "6efded68-f95c-4b9b-e038-7fb496d135b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (5731, 2)\n",
            "TRAIN Dataset: (4585, 2)\n",
            "TEST Dataset: (1146, 2)\n"
          ]
        }
      ],
      "source": [
        "class PytorchDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, tag_to_id, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.tag_to_id = tag_to_id\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        label_all_tokens = True\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            [list(self.data.tokens[index])],\n",
        "            truncation=True,\n",
        "            is_split_into_words=True,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "        labels = []\n",
        "        for i, label in enumerate([list(self.data.ner_tags[index])]):\n",
        "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "            previous_word_idx = None\n",
        "            label_ids = []\n",
        "            for word_idx in word_ids:\n",
        "                if word_idx is None:\n",
        "                    label_ids.append(-100)\n",
        "                elif label[word_idx] == \"0\":\n",
        "                    label_ids.append(0)\n",
        "                elif word_idx != previous_word_idx:\n",
        "                    label_ids.append(self.tag_to_id[label[word_idx]])\n",
        "                else:\n",
        "                    label_ids.append(self.tag_to_id[label[word_idx]] if label_all_tokens else -100)\n",
        "                previous_word_idx = word_idx\n",
        "            labels.append(label_ids)\n",
        "\n",
        "        tokenized_inputs[\"labels\"] = labels\n",
        "\n",
        "        single_tokenized_input = {}\n",
        "        for k, v in tokenized_inputs.items():\n",
        "            single_tokenized_input[k] = torch.as_tensor(v[0])\n",
        "\n",
        "        return single_tokenized_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "def create_model_inputs(dataset, tag_to_id):\n",
        "\n",
        "    train_dataset = dataset.sample(frac=TRAIN_EXAMPLES_RATIO, random_state=200)\n",
        "    test_dataset = dataset.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    print(\"FULL Dataset: {}\".format(dataset.shape))\n",
        "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "    print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "    train = PytorchDataset(train_dataset, tokenizer, tag_to_id, MAX_LEN)\n",
        "    test = PytorchDataset(test_dataset, tokenizer, tag_to_id, MAX_LEN)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "\n",
        "tag_counter = Counter([tag for tags in ner_dataset[\"ner_tags\"] for tag in tags])\n",
        "tag_to_id = {tag: ix for ix, tag in enumerate(tag_counter.keys())}\n",
        "train_set, test_set = create_model_inputs(ner_dataset, tag_to_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cQCqJC_R9vl"
      },
      "source": [
        "### Training and Evaluation\n",
        "\n",
        "At this step, we are fine-tuning the model by training the model with pre-trained weights. The method will save the model object at Layer as well as logging the intermediate training loss and the final evaluation results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq5vduWOR9vl",
        "outputId": "00d5a594-fde9-4877-e6ae-cea4e66bd94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  un_ner_fine-tuned_b… ━━━━━━━━━━ DONE [0:14:34]                              \n",
            "    ↳ https://app.layer.ai/kaankarakeben/united-nations-ner-finetuning/models/u \n",
            "    n_ner_fine-tuned_bert?v=1.16                                                \n"
          ]
        }
      ],
      "source": [
        "def train(train_set):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from transformers import BertForTokenClassification\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    train_params = {\"batch_size\": TRAIN_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
        "    training_loader = DataLoader(train_set, **train_params)\n",
        "\n",
        "    model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag_to_id))\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"Training epoch: {epoch + 1}\")\n",
        "        tr_loss, tr_accuracy = 0, 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        tr_preds, tr_labels = [], []\n",
        "\n",
        "        model.train()  # model in training mode\n",
        "\n",
        "        for idx, batch in enumerate(training_loader):\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(DEVICE, dtype=torch.long)\n",
        "            mask = batch[\"attention_mask\"].to(DEVICE, dtype=torch.long)\n",
        "            labels = batch[\"labels\"].to(DEVICE, dtype=torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            tr_logits = outputs[1]\n",
        "            tr_loss += loss.item()\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples += labels.size(0)\n",
        "\n",
        "            if idx % 100 == 0:\n",
        "                loss_step = tr_loss / nb_tr_steps\n",
        "                print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "                layer.log({\"Training loss per 100 training steps\": loss_step}, step=int(idx/100)+1)\n",
        "\n",
        "            # compute training accuracy\n",
        "            flattened_targets = labels.view(-1)\n",
        "            active_logits = tr_logits.view(-1, model.num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "\n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100\n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            tr_labels.extend(labels)\n",
        "            tr_preds.extend(predictions)\n",
        "\n",
        "            tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "            # gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=MAX_GRAD_NORM)\n",
        "\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        epoch_loss = tr_loss / nb_tr_steps\n",
        "        tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "        print(f\"Training loss epoch: {epoch_loss}\")\n",
        "        print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model, test_set, tag_to_id):\n",
        "    from sklearn.metrics import classification_report\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    \n",
        "    id_to_tag = {ix: tag for tag, ix in tag_to_id.items()}\n",
        "    test_params = {\"batch_size\": VALID_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
        "    testing_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "    model.eval()  # model in evaluation mode\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(DEVICE, dtype=torch.long)\n",
        "            mask = batch[\"attention_mask\"].to(DEVICE, dtype=torch.long)\n",
        "            labels = batch[\"labels\"].to(DEVICE, dtype=torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            eval_logits = outputs[1]\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "\n",
        "            if idx % 100 == 0:\n",
        "                loss_step = eval_loss / nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "                layer.log({\"Validation loss per 100 evaluation steps\": loss_step}, step=int(idx/100)+1)\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "\n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100\n",
        "\n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [id_to_tag[id.item()] for id in eval_labels]\n",
        "    predictions = [id_to_tag[id.item()] for id in eval_preds]\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    layer.log({\"Test Loss\": eval_loss, \"Test Accuracy\": eval_accuracy})\n",
        "\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    print(classification_report(labels, predictions))\n",
        "    layer.log(classification_report(labels, predictions, output_dict=True))\n",
        "\n",
        "\n",
        "@pip_requirements(packages=[\"transformers\", \"sklearn\", \"torch\"])\n",
        "@fabric(\"f-gpu-small\")\n",
        "@model(\"un_ner_fine-tuned_bert\")\n",
        "def run_model_training():\n",
        "    model = train(train_set)\n",
        "    evaluate(model, test_set, tag_to_id)\n",
        "    return model\n",
        "\n",
        "layer.run([run_model_training])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = layer.get_model(\"kaankarakeben/united-nations-ner-finetuning/models/un_ner_fine-tuned_bert:1.16\").get_train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tJh41YHZbN",
        "outputId": "f4950d56-6526-4893-f2ca-49cb5a31b60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⠏  un_ner_fine-tuned_b… ━━━━━━━━━━ LOADED [0:00:07] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi9JnOsVR9vm"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Looking at the test set, we are able to achieve an accuracy of 98% and an F1 score of 89% with our trained model. We are pretty accurate with detecting PERSON entities but having low recall with MISCELLANEOUS compared to others. Overall impressive results with a relatively small amount of annotated data!\n",
        "\n",
        "``` Plain Text\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "       I-LOC       0.93      0.94      0.94       806\n",
        "      I-MISC       0.75      0.73      0.74       636\n",
        "       I-ORG       0.82      0.92      0.87       681\n",
        "       I-PER       0.97      0.99      0.98       144\n",
        "           O       1.00      0.99      0.99     28756\n",
        "\n",
        "    accuracy                           0.99     31023\n",
        "   macro avg       0.90      0.91      0.90     31023\n",
        "weighted avg       0.99      0.99      0.99     31023\n",
        "```\n",
        "\n",
        "Lastly we'll have a look at sentence outside test and train sets to see the model in action.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQRwvY3NR9vm",
        "outputId": "399d77d3-9a21-41c0-fa95-b016389f9365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Expressing', 'deep', 'concern', 'about', 'the', 'impact', 'of', 'the', 'food', 'security', 'crisis', 'on', 'the', 'assistance', 'provided', 'by', 'United', 'Nations', 'humanitarian', 'agencies,', 'in', 'particular', 'the', 'World', 'Food', 'Programme.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG']\n"
          ]
        }
      ],
      "source": [
        "def predict_ner_example(sentence):\n",
        "    inputs = tokenizer(\n",
        "        sentence.split(),\n",
        "        is_split_into_words=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    id_to_tag = {ix: tag for tag, ix in tag_to_id.items()}\n",
        "    \n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs[\"attention_mask\"]\n",
        "    # forward pass\n",
        "    outputs = model(ids, attention_mask=mask)\n",
        "    logits = outputs[0]\n",
        "\n",
        "    active_logits = logits.view(-1, model.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
        "    flattened_predictions = torch.argmax(\n",
        "        active_logits, axis=1\n",
        "    )  # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "    token_predictions = [id_to_tag[i] for i in flattened_predictions.cpu().numpy()]\n",
        "    wp_preds = list(zip(tokens, token_predictions))  # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "    prediction = []\n",
        "    for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
        "        # only predictions on first word pieces are important\n",
        "        if mapping[0] == 0 and mapping[1] != 0:\n",
        "            prediction.append(token_pred[1])\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "    return sentence, prediction\n",
        "\n",
        "sentence = \"\"\"Expressing deep concern about the impact of the food security crisis on the\n",
        "assistance provided by United Nations humanitarian agencies, in particular the World\n",
        "Food Programme.\"\"\"\n",
        "\n",
        "sentence, prediction = predict_ner_example(sentence)\n",
        "print(sentence.split())\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M130kMklR9vn"
      },
      "source": [
        "##  Conclusion\n",
        "\n",
        "Extracting named entities from text has many uses that transform the way we interact with these documents. Usage of pre-trained models like BERT and libraries such as Huggingface and PyTorch makes it easy for us to fine-tune general-purpose models into specialist ones. However, for a data scientist life doesn't end with the trained model at a notebook. Features we have shown from Layer allow us to follow the best MLOps practices in building, tracking, and logging all of our artifacts. When all these technologies combine, long-lasting value is unlocked.\n",
        "\n",
        "Blog posts and tutorial I find useful in preparation for this work:\n",
        "\n",
        "https://medium.com/@andrewmarmon/fine-tuned-named-entity-recognition-with-hugging-face-bert-d51d4cb3d7b5\n",
        "\n",
        "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=zPDla1mmZiax\n",
        "\n",
        "https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/\n",
        "\n",
        "https://jalammar.github.io/illustrated-bert/\n",
        "\n",
        "https://huggingface.co/docs/transformers/tasks/token_classification\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "71850e9f25a0f79f75822aa458fa673d472e7f4ffc7cab23b5caf4c00ad2944b"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "un-ner-finetune-pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87ac34b4d5be4811a58de0fb1ceed9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a057c2c607ba4ba4a5ca5f15579d0ab5",
              "IPY_MODEL_d304f33daf2e442ebafe045d5689aa67",
              "IPY_MODEL_f041d98a6d99436c88f8314b476f86bf"
            ],
            "layout": "IPY_MODEL_330aae7d5fe1433ca12e177b97cddfc5"
          }
        },
        "a057c2c607ba4ba4a5ca5f15579d0ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edb4da206724db7a032daea0aae3bbb",
            "placeholder": "​",
            "style": "IPY_MODEL_86ece372ea304cb5b4890f6d920e4269",
            "value": "Downloading: 100%"
          }
        },
        "d304f33daf2e442ebafe045d5689aa67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbda1a38a9ec4e509eb9c40051bf3427",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea56c606ec2a4cb0a087634906fe5450",
            "value": 28
          }
        },
        "f041d98a6d99436c88f8314b476f86bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b1d9d26be847e1896b3511287fd2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_cf1712a2ba6a442f998ec49b11c9a570",
            "value": " 28.0/28.0 [00:00&lt;00:00, 132B/s]"
          }
        },
        "330aae7d5fe1433ca12e177b97cddfc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edb4da206724db7a032daea0aae3bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ece372ea304cb5b4890f6d920e4269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbda1a38a9ec4e509eb9c40051bf3427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea56c606ec2a4cb0a087634906fe5450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4b1d9d26be847e1896b3511287fd2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf1712a2ba6a442f998ec49b11c9a570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e8ff8fd1204a2cb2816c020b22be17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_568b6fb9f0df48fea3eabce81d459eee",
              "IPY_MODEL_7eee4edf3a3e4a9c83b9917efaa4e46c",
              "IPY_MODEL_1c2b41aa75c049dc9bc6ea9f2f5e4b31"
            ],
            "layout": "IPY_MODEL_81206ea8c2de472dadd8eb46e5a20115"
          }
        },
        "568b6fb9f0df48fea3eabce81d459eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c33e5b507e094bb5bed7ffabdf0e57ec",
            "placeholder": "​",
            "style": "IPY_MODEL_047e4438fa23453794be01930012a5dd",
            "value": "Downloading: 100%"
          }
        },
        "7eee4edf3a3e4a9c83b9917efaa4e46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394cd36238654af99f975be2f4c6623e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70a44ab938054561928c45f85fcaa7bd",
            "value": 231508
          }
        },
        "1c2b41aa75c049dc9bc6ea9f2f5e4b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d420cac29a7144968f408a5b8ef76977",
            "placeholder": "​",
            "style": "IPY_MODEL_de8cb135bc7541f48e665c28d59cdfe8",
            "value": " 226k/226k [00:00&lt;00:00, 4.64kB/s]"
          }
        },
        "81206ea8c2de472dadd8eb46e5a20115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33e5b507e094bb5bed7ffabdf0e57ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047e4438fa23453794be01930012a5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "394cd36238654af99f975be2f4c6623e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a44ab938054561928c45f85fcaa7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d420cac29a7144968f408a5b8ef76977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8cb135bc7541f48e665c28d59cdfe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c2971ec486481fa1802a2c4657e73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8f15011a94e4435a4288ac90eea772e",
              "IPY_MODEL_44dbe2e8e7d149258e300870184f012d",
              "IPY_MODEL_398ccf3e12524cdc9a78b54a64436bb8"
            ],
            "layout": "IPY_MODEL_d0fc4291111f4cfd854197043acbdb89"
          }
        },
        "f8f15011a94e4435a4288ac90eea772e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3ae477fe10e481c8a8ebe34083ba9ac",
            "placeholder": "​",
            "style": "IPY_MODEL_988b1898cc214364b0f5cb460feabbae",
            "value": "Downloading: 100%"
          }
        },
        "44dbe2e8e7d149258e300870184f012d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc66bd78db5d4e84be8a6d81f53e7dc4",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_364b87333d934b5393768fc52c4172e1",
            "value": 466062
          }
        },
        "398ccf3e12524cdc9a78b54a64436bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b1abd2d51f4c58b1830c59e7b2aa67",
            "placeholder": "​",
            "style": "IPY_MODEL_7ea9e0f05e1349138d02ffce69dc66bd",
            "value": " 455k/455k [00:00&lt;00:00, 6.28kB/s]"
          }
        },
        "d0fc4291111f4cfd854197043acbdb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ae477fe10e481c8a8ebe34083ba9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988b1898cc214364b0f5cb460feabbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc66bd78db5d4e84be8a6d81f53e7dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364b87333d934b5393768fc52c4172e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2b1abd2d51f4c58b1830c59e7b2aa67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea9e0f05e1349138d02ffce69dc66bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e937297d484a1d908d0b740820fd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8000df05e29a498a9b49b28a502c4feb",
              "IPY_MODEL_57a70adb0783425995786c03e29325ce",
              "IPY_MODEL_b615799b4ecd4aea8614d2591fbd29ad"
            ],
            "layout": "IPY_MODEL_12d3e45a5dde4cfc89c3dc6b5d043f1a"
          }
        },
        "8000df05e29a498a9b49b28a502c4feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4437d6f248714a1cb16f297bb6bb72bb",
            "placeholder": "​",
            "style": "IPY_MODEL_217485a83b6a411ebb970ee52436da2d",
            "value": "Downloading: 100%"
          }
        },
        "57a70adb0783425995786c03e29325ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd29a01768c44429554a0a2dc30feae",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc56d692f49429f8ee5ceb8fc72db76",
            "value": 570
          }
        },
        "b615799b4ecd4aea8614d2591fbd29ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e31c2aa6784786832fd0db97b87f23",
            "placeholder": "​",
            "style": "IPY_MODEL_2c881835c3c845a1af8e8e248bfbc674",
            "value": " 570/570 [00:00&lt;00:00, 3.98kB/s]"
          }
        },
        "12d3e45a5dde4cfc89c3dc6b5d043f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4437d6f248714a1cb16f297bb6bb72bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217485a83b6a411ebb970ee52436da2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd29a01768c44429554a0a2dc30feae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc56d692f49429f8ee5ceb8fc72db76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28e31c2aa6784786832fd0db97b87f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c881835c3c845a1af8e8e248bfbc674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}