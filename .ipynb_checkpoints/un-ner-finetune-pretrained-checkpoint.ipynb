{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning BERT For Named Entity Recognition On United Nations Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans understand the world by putting labels on things and examining how these labels relate to each other. A reflection of this natural language processing and information retrievial world is technique called Named Entity Recognition (NER). The objective is to detect the entity type of segments of text in a document. These entities could be organizations, locations, persons or others. \n",
    "\n",
    "In this blog post, I will go through an example for learning an named entity recognition model on specific domain. Instead of creating a NER model from scratch, I will use transfer-learning by taking pre-trained language model, BERT, trained on a large number of general examples and fine-tune that neural network on a very specific type of domain. \n",
    "\n",
    "Alongside the tutorial on learning an NER model, I will run this project on Layer in order to make use of their metadata store for storing and tracking the datasets and model artifacts as well as their free GPU compute instances. \n",
    "\n",
    "Firstly, let's define the problem. We are working with a set of documents from United Nations (UN). Diplomatic jargon is the norm at the UN and these documents contain many specific entities that we don't encounter in everyday language such as the Office for the Coordination of Humanitarian Affairs of the Secretariat and the Office of the United\n",
    "Nations High Commissioner for Refugees. We would like to automatically detect these entities with their corresponding types. With the entities flagged, we can power many interesting use cases such as information retrivial, question/answering, document similarity etc. \n",
    "\n",
    "The dataset is generously made available to the public by Leslie Huang. It consists of transcribed speeches given at the UN General Assembly from 1993-2016, which were scraped from the UN website, parsed (e.g. from PDF), and cleaned. More than 50,000 tokens were manually annotated for NER tags.\n",
    "https://github.com/leslie-huang/UN-named-entity-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing/Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a project at Layer so that we can define a reproducible project and dataset and artifacts logged along with parameters for future reference. Layer helps you build, train and track all your machine learning project metadata including ML models and datasets‍ with semantic versioning. It also allows you to use their cloud infrastucture free of charge including access to GPUs. We will work with a pretrained transformer based language model; so added processing power is very welcome.\n",
    "\n",
    "We will start by installing the necessary libraries. Here we log in to Layer and initialize our ML project called \"united-nations-ner-finetuning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "import layer\n",
    "from layer.decorators import dataset, model, pip_requirements, fabric, resources\n",
    "\n",
    "layer.login()\n",
    "layer.init(\"united-nations-ner-finetuning\")\n",
    "\n",
    "TRAIN_EXAMPLES_RATIO = 0.8\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "!git clone https://github.com/leslie-huang/UN-named-entity-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the ML metadatastore, we will now clone the Github repository that hosts the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/leslie-huang/UN-named-entity-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "At this step, we will load the tagged documents from both training and test sets and store them in a DataFrame.\n",
    "As you may have noticed, we are using decorators from Layer to define a dataset artifact that will be logged on our cloud project at Layer. By calling \"layer.run()\" we will running the function \"create_dataset\" on the cloud infrastructure.\n",
    "\n",
    "You may have also noticed we are logging some text metadata with the raw dataset. This enriches our ML project at the readability and reproducability level. As code is more often read then written, so are ML projects. \n",
    "\n",
    "Next, we will get the dataset into local memory by calling it from Layer with layer.get_dataset() function. \n",
    "\n",
    "Next we will examine the dataset. The annotation follows us specific Named Entity Recognition annotation scheme called IOB-tagging. It stands for Inside-Outside-Beginning. The document is tagged at the word level and entities sometimes comes in word groups. To note the entities that cover a few words we use the Beginning (B) and Inside (I) tags. \n",
    "Example: Tim Cook works at Apple. \n",
    "[Tim, Cook, works, at, Apple] -> [B-PER, I-PER, O, 0, B-ORG]\n",
    "\n",
    "Our dataset consists of two columns where each item is a list. At \"tokens\" column, we have words in the document in a list. In the \"ner_tags\" column, we have the corresponding tags.\n",
    "\n",
    "We will now create a Counter object from the NER tags. As expected the most common tag is \"O\" denoting \"Outside\" for words that are not a part of a named entity. Second is \"I-ORG\" tag denoting organisation entities and next in line is location.\n",
    "An interesting find is that while we have Inside (I) tags, we don't have their beginning (B) tags. We also have some typos that have very low representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcc9bcc70f4472fba865d928724f23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_tags(tags, tags_to_remove):\n",
    "    clean_list = []\n",
    "    for tag in list(tags):\n",
    "        if tag != \"O\":\n",
    "            if tag not in tags_to_remove:\n",
    "                clean_list.append(tag)\n",
    "            else:\n",
    "                clean_list.append(\"O\")\n",
    "        else:\n",
    "            clean_list.append(\"O\")\n",
    "    return clean_list\n",
    "\n",
    "@dataset(\"un_ner_dataset\")\n",
    "@resources(path=\"./UN-named-entity-recognition\")\n",
    "def create_dataset():\n",
    "    import os\n",
    "    import itertools\n",
    "    import pandas as pd\n",
    "    from collections import Counter\n",
    "    \n",
    "    directories = [\n",
    "        \"./UN-named-entity-recognition/tagged-training/\",\n",
    "        \"./UN-named-entity-recognition/tagged-test/\",\n",
    "    ]\n",
    "    data_files = []\n",
    "    for dir in directories:\n",
    "        for filename in os.listdir(dir):\n",
    "            file_path = os.path.join(dir, filename)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "                lines = f.readlines()\n",
    "                split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == \"\\n\") if not x]\n",
    "                tokens = [[x.split(\"\\t\")[0] for x in y] for y in split_list]\n",
    "                entities = [[x.split(\"\\t\")[1][:-1] for x in y] for y in split_list]\n",
    "                data_files.append(pd.DataFrame({\"tokens\": tokens, \"ner_tags\": entities}))\n",
    "\n",
    "    dataset = pd.concat(data_files).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "    # Cleaning and removing bad tags\n",
    "    pre_cleanup_tag_counter = Counter([tag for tags in dataset[\"ner_tags\"] for tag in tags])\n",
    "    tags_to_remove = [\"I-PRG\", \"I-I-MISC\", \"I-OR\", \"VMISC\", \"I-\", \"0\"]\n",
    "    dataset[\"ner_tags\"] = dataset[\"ner_tags\"].apply(lambda x: clean_tags(x, tags_to_remove))\n",
    "    tag_counter = Counter([tag for tags in dataset[\"ner_tags\"] for tag in tags])\n",
    "    dataset_description = \"\"\"The corpus consists of a sample of transcribed speeches given at the UN General Assembly \n",
    "    from 1993-2016, which were scraped from the UN website, parsed (e.g. from PDF), and cleaned. More than 50,000 tokens \n",
    "    in the test data were manually tagged for Named Entity Recognition (O - Not a Named Entity; I-PER - Person; I-ORG - \n",
    "    Organization; I-LOC - Location; I-MISC - Other Named Entity).\"\"\"\n",
    "    layer.log({\"# Examples\": len(dataset)})\n",
    "    layer.log({\"Dataset Description\": dataset_description})\n",
    "    layer.log({\"Source\": \"https://github.com/leslie-huang/UN-named-entity-recognition\"})\n",
    "    layer.log({\"Raw Tags Counter\": pre_cleanup_tag_counter})\n",
    "    layer.log({\"Clean Tags Counter\": tag_counter})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "ner_dataset = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05ec98047764e2fb3880b96b4c00723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pip_requirements(packages=[\"transformers\"])\n",
    "@fabric(\"f-medium\")\n",
    "@model(name=\"bert-base-uncased-tokenizer\")\n",
    "def download_tokenizer():\n",
    "    from transformers import BertTokenizerFast\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = download_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (5731, 2)\n",
      "TRAIN Dataset: (4585, 2)\n",
      "TEST Dataset: (1146, 2)\n"
     ]
    }
   ],
   "source": [
    "class PytorchDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, tag_to_id, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.tag_to_id = tag_to_id\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        label_all_tokens = True\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            [list(self.data.tokens[index])],\n",
    "            truncation=True,\n",
    "            is_split_into_words=True,\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        labels = []\n",
    "        for i, label in enumerate([list(self.data.ner_tags[index])]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif label[word_idx] == \"0\":\n",
    "                    label_ids.append(0)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(self.tag_to_id[label[word_idx]])\n",
    "                else:\n",
    "                    label_ids.append(self.tag_to_id[label[word_idx]] if label_all_tokens else -100)\n",
    "                previous_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "        single_tokenized_input = {}\n",
    "        for k, v in tokenized_inputs.items():\n",
    "            single_tokenized_input[k] = torch.as_tensor(v[0])\n",
    "\n",
    "        return single_tokenized_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "def create_model_inputs(dataset, tag_to_id):\n",
    "\n",
    "    train_dataset = dataset.sample(frac=TRAIN_EXAMPLES_RATIO, random_state=200)\n",
    "    test_dataset = dataset.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "    print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "    train = PytorchDataset(train_dataset, tokenizer, tag_to_id, MAX_LEN)\n",
    "    test = PytorchDataset(test_dataset, tokenizer, tag_to_id, MAX_LEN)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "tag_counter = Counter([tag for tags in ner_dataset[\"ner_tags\"] for tag in tags])\n",
    "tag_to_id = {tag: ix for ix, tag in enumerate(tag_counter.keys())}\n",
    "train_set, test_set = create_model_inputs(ner_dataset, tag_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2092712c11ce49edb60c4e98446550e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Some weights of the model checkpoint at bert-base-uncased were not used when initializing \n",
       "BertForTokenClassification: ['cls.predictions.transform.dense.bias', \n",
       "'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', \n",
       "'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', \n",
       "'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
       "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of \n",
       "a model trained on another task or with another architecture (e.g. initializing a \n",
       "BertForSequenceClassification model from a BertForPreTraining model).\n",
       "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint\n",
       "of a model that you expect to be exactly identical (initializing a \n",
       "BertForSequenceClassification model from a BertForSequenceClassification model).\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Some weights of the model checkpoint at bert-base-uncased were not used when initializing \n",
       "BertForTokenClassification: ['cls.predictions.transform.dense.bias', \n",
       "'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', \n",
       "'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', \n",
       "'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
       "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of \n",
       "a model trained on another task or with another architecture (e.g. initializing a \n",
       "BertForSequenceClassification model from a BertForPreTraining model).\n",
       "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint\n",
       "of a model that you expect to be exactly identical (initializing a \n",
       "BertForSequenceClassification model from a BertForSequenceClassification model).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Some weights of BertForTokenClassification were not initialized from the model checkpoint at \n",
       "bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
       "You should probably TRAIN this model on a down-stream task to be able to use it for \n",
       "predictions and inference.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Some weights of BertForTokenClassification were not initialized from the model checkpoint at \n",
       "bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
       "You should probably TRAIN this model on a down-stream task to be able to use it for \n",
       "predictions and inference.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training epoch: 1\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training epoch: 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 1.7480363845825195\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 1.7480363845825195\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.4114809680988293\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.4114809680988293\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.2842781590992835\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.2842781590992835\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.2184543209978104\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.2184543209978104\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.18563807239242716\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.18563807239242716\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.16249154775567026\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.16249154775567026\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.15013419074307005\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.15013419074307005\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.13808446971748753\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.13808446971748753\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.12886089010855367\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.12886089010855367\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.12047622159015405\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.12047622159015405\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.11296096230128112\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.11296096230128112\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss per 100 training steps: 0.10747198546045188\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss per 100 training steps: 0.10747198546045188\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training loss epoch: 0.1053092759686182\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training loss epoch: 0.1053092759686182\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training accuracy epoch: 0.9689969839644262\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training accuracy epoch: 0.9689969839644262\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.0006706120911985636\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.0006706120911985636\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.03308585147825208\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.03308585147825208\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.040037732078480666\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.040037732078480666\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.045820159135824164\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.045820159135824164\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.046044706446356706\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.046044706446356706\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation loss per 100 evaluation steps: 0.04617484640831986\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation loss per 100 evaluation steps: 0.04617484640831986\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation Loss: 0.0465435694060394\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation Loss: 0.0465435694060394\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Validation Accuracy: 0.9853115881748523\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Validation Accuracy: 0.9853115881748523\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "       I-LOC       0.90      0.98      0.94       780\n",
       "      I-MISC       0.71      0.82      0.76       603\n",
       "       I-ORG       0.84      0.84      0.84       748\n",
       "       I-PER       0.90      0.98      0.94       178\n",
       "           O       1.00      0.99      0.99     29144\n",
       "\n",
       "    accuracy                           0.98     31453\n",
       "   macro avg       0.87      0.92      0.90     31453\n",
       "weighted avg       0.98      0.98      0.98     31453\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "       I-LOC       0.90      0.98      0.94       780\n",
       "      I-MISC       0.71      0.82      0.76       603\n",
       "       I-ORG       0.84      0.84      0.84       748\n",
       "       I-PER       0.90      0.98      0.94       178\n",
       "           O       1.00      0.99      0.99     29144\n",
       "\n",
       "    accuracy                           0.98     31453\n",
       "   macro avg       0.87      0.92      0.90     31453\n",
       "weighted avg       0.98      0.98      0.98     31453\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train(train_set):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from transformers import BertForTokenClassification\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    train_params = {\"batch_size\": TRAIN_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "    training_loader = DataLoader(train_set, **train_params)\n",
    "\n",
    "    model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag_to_id))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Training epoch: {epoch + 1}\")\n",
    "        tr_loss, tr_accuracy = 0, 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        tr_preds, tr_labels = [], []\n",
    "\n",
    "        model.train()  # model in training mode\n",
    "\n",
    "        for idx, batch in enumerate(training_loader):\n",
    "\n",
    "            ids = batch[\"input_ids\"].to(DEVICE, dtype=torch.long)\n",
    "            mask = batch[\"attention_mask\"].to(DEVICE, dtype=torch.long)\n",
    "            labels = batch[\"labels\"].to(DEVICE, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            tr_logits = outputs[1]\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples += labels.size(0)\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = tr_loss / nb_tr_steps\n",
    "                print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "            # compute training accuracy\n",
    "            flattened_targets = labels.view(-1)\n",
    "            active_logits = tr_logits.view(-1, model.num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "\n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            tr_labels.extend(labels)\n",
    "            tr_preds.extend(predictions)\n",
    "\n",
    "            tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=MAX_GRAD_NORM)\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = tr_loss / nb_tr_steps\n",
    "        tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "        print(f\"Training loss epoch: {epoch_loss}\")\n",
    "        print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, test_set, tag_to_id):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    id_to_tag = {ix: tag for tag, ix in tag_to_id.items()}\n",
    "    test_params = {\"batch_size\": VALID_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "    testing_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "    model.eval()  # model in evaluation mode\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    device = \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            labels = batch[\"labels\"].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            eval_logits = outputs[1]\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = eval_loss / nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "\n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [id_to_tag[id.item()] for id in eval_labels]\n",
    "    predictions = [id_to_tag[id.item()] for id in eval_preds]\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    layer.log({\"Test Loss\": eval_loss, \"Test Accuracy\": eval_accuracy})\n",
    "\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    print(classification_report(labels, predictions))\n",
    "    layer.log(classification_report(labels, predictions, output_dict=True))\n",
    "\n",
    "\n",
    "@pip_requirements(packages=[\"transformers\", \"sklearn\", \"torch\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(\"un_ner_fine-tuned_bert\")\n",
    "def run_model_training():\n",
    "    model = train(train_set)\n",
    "    evaluate(model, test_set, tag_to_id)\n",
    "    return model\n",
    "\n",
    "model = run_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Expressing', 'deep', 'concern', 'about', 'the', 'impact', 'of', 'the', 'food', 'security', 'crisis', 'on', 'the', 'assistance', 'provided', 'by', 'United', 'Nations', 'humanitarian', 'agencies,', 'in', 'particular', 'the', 'World', 'Food', 'Programme.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "def predict_ner_example(sentence):\n",
    "    inputs = tokenizer(\n",
    "        sentence.split(),\n",
    "        is_split_into_words=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    id_to_tag = {ix: tag for tag, ix in tag_to_id.items()}\n",
    "    \n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    # forward pass\n",
    "    outputs = model(ids, attention_mask=mask)\n",
    "    logits = outputs[0]\n",
    "\n",
    "    active_logits = logits.view(-1, model.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
    "    flattened_predictions = torch.argmax(\n",
    "        active_logits, axis=1\n",
    "    )  # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "    token_predictions = [id_to_tag[i] for i in flattened_predictions.cpu().numpy()]\n",
    "    wp_preds = list(zip(tokens, token_predictions))  # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "    prediction = []\n",
    "    for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
    "        # only predictions on first word pieces are important\n",
    "        if mapping[0] == 0 and mapping[1] != 0:\n",
    "            prediction.append(token_pred[1])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return sentence, prediction\n",
    "\n",
    "sentence = \"\"\"Expressing deep concern about the impact of the food security crisis on the\n",
    "assistance provided by United Nations humanitarian agencies, in particular the World\n",
    "Food Programme.\"\"\"\n",
    "\n",
    "sentence, prediction = predict_ner_example(sentence)\n",
    "print(sentence.split())\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71850e9f25a0f79f75822aa458fa673d472e7f4ffc7cab23b5caf4c00ad2944b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
